{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of tweets - opinions on air carriers from February 2015\n",
    "\n",
    "### Step 1: import of tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fce10577-7807-ca76-4de9-15e6319715ca"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#limit on size of vocabualry dictionary used in tweets\n",
    "vocab_size = 500\n",
    "\n",
    "data = pd.read_csv('Tweets.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: data transformation and splitting into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "018f3cbd-850b-5367-ec0e-42cd5cda2d86"
   },
   "outputs": [],
   "source": [
    "#tokenizing of words in tweets\n",
    "tok = Tokenizer(num_words=vocab_size, split=' ')\n",
    "tok.fit_on_texts(data['text'].values)\n",
    "X = tok.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)\n",
    "\n",
    "#extraction of sentiment category\n",
    "categories = pd.get_dummies(data['airline_sentiment'])\n",
    "labels = categories.keys()\n",
    "Y = categories.values\n",
    "\n",
    "#splitting into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10, random_state=42)\n",
    "print('train_features shape: ', X_train.shape)\n",
    "print('test_features shape: ', X_test.shape)\n",
    "print('train_labels shape: ', Y_train.shape)\n",
    "print('test_labels shape: ', Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Definition of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cb00f408-4eb2-112b-518f-907d951e53b7"
   },
   "outputs": [],
   "source": [
    "#definition of model\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "# exercise 1\n",
    "# Add layers to the model:\n",
    "# - Embedding - it should get vectors of dictionary size lenght (vocab_size) on the input and transform them into vectors of the lenght equal to 32\n",
    "# - 1 LSTM layer with number of units equal to 10\n",
    "# - Dens - a base of classification (how many outputs it should have?)\n",
    "\n",
    "# - learning process should be based on function starty categorical_crossentropy\n",
    "# - choose 'sgd' as a method for model optimization\n",
    "# - model should return accuracy metric (categorical_accuracy)\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# exercise 2 - zamien\n",
    "# Change model optimization method to 'adam'.\n",
    "# Compare results with those obtained with 'sgd' and explain differences.\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# exercise 3\n",
    "# Add additional LSTM layer with number of units equal to 10.\n",
    "# Perform learning process with 'adam' and 'sgd' methods.\n",
    "\n",
    "\n",
    "## -- beginning of your solution\n",
    "\n",
    "## -- end of your solution\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a6da6544-a312-d6d5-7e54-f1ecb15259ee"
   },
   "outputs": [],
   "source": [
    "# Add:\n",
    "# - network learning on X_train, Y_train with parameters: batch_size = 16 and number of epochs = 5\n",
    "# - accuracy checking on test data: X_test,Y_test\n",
    "\n",
    "## -- beginning of your solution\n",
    "\n",
    "## -- end of your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Sentiment prediction on exemplary tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0d357960-de37-600e-334e-74be5ba4d168",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prediction on exemplary tweets\n",
    "def predict(tweet):\n",
    "    padded_tweet = pad_sequences(tok.texts_to_sequences([tweet]), maxlen=X.shape[1])\n",
    "    scores = model.predict(padded_tweet)[0]\n",
    "    index = np.argmax(scores)\n",
    "    print(f'Tweet:\\\"{tweet}\\\"')\n",
    "    print(f'predicted sentiment: {labels[index]}, confidence: {scores[index]}\\n')\n",
    "\n",
    "#expected prediction: negative\n",
    "predict(\"@united been up since 4am cheers for this delay and then cancellation of the flight\")\n",
    "#expected prediction: positive\n",
    "predict(\"@united Terrific. Many thanks. Looking forward to being back on UA tomorrow. Had a great flight up to Vancouver.\")\n",
    "#expected prediction: neutral\n",
    "predict(\"Dallas, Texas to Marrakesh, Morocco for only $442 roundtrip with @FlySWISS & @united.\")"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 33,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
